{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1642dc-8124-4775-ab3f-2c6b1759ae00",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Entity Matcher in production - contextualize time series to assets using Cognite Functions\n",
    "\n",
    "## Table Of Contents\n",
    "\n",
    "1. [Introduction](#introduction)\n",
    "2. [Authenticating with CDF](#authentication)\n",
    "3. [Getting a copy of test-data](#test-data)\n",
    "4. [Defining and deploying our Cognite Function](#deploy-cog-fun)\n",
    "5. [Calling our Cognite Function](#calling-func)\n",
    "6. [Scheduling our Cognite Function](#schedule-cog-fun)\n",
    "\n",
    "## Introduction <a name=\"introduction\"></a>\n",
    "\n",
    "After ingesting some assets and time series to CDF, a common use case is to perform some sort of contextualization by mapping time series to assets. Quite often, there is not an identical match between a field on the time series to e.g. the asset name, but a somewhat similar name. The most typical example we use in Cognite is the asset `21PT1019` and the time series `IAA_21PT1019.PV` or similar.\n",
    "\n",
    "In our contextualization toolbox (an [API](https://docs.cognite.com/api/playground/#operation/entityMatchingFit) with a corresponding  [SDK](https://cognite-sdk-experimental.readthedocs-hosted.com/en/latest/cognite.html#contextualization)), we have a tool to solve this problem called entity matching. Entity matching means joining two datasets on a common key with fuzzyness, and our implementation is a machine learning model that can be trained supervised or unsupervised. \n",
    "\n",
    "In this tutorial, we'll take the time series and assets from the `publicdata` tenant, and deploy a Cognite Function that performs entity matching to map the time series to assets, and schedule it to run periodically. This can be used out of the box for many customers as an initial contextualization step.\n",
    "\n",
    "We will provide you with the code needed to get a copy of the test data in your own tenant.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "We will be using the [experimental Cognite SDK](https://cognite-sdk-experimental.readthedocs-hosted.com/en/latest/cognite.html#functions). \n",
    "To run this example, you first need to install this package:\n",
    "\n",
    "```\n",
    "pip install cognite-sdk-experimental\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c2ef63-361d-4a76-87a9-cdaa1416e3a4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Authenticating with CDF <a name=\"authentication\"></a>\n",
    "\n",
    "In order to connect to CDF we will authenticate using Azure AD. There are several ways to do this, all of them outlined in the [Authenticate with Azure AD](https://docs.cognite.com/dev/guides/sdk/python/python_auth_oidc/) documentation. We will in this example use [**client credentials**](https://docs.cognite.com/dev/guides/sdk/python/python_auth_oidc/#authenticate-with-client-secret). There are pros and cons to each authentication method. Here we choose client-credentials due to little additional work needed to get up and running.\n",
    "\n",
    "This means that we need the following:\n",
    "\n",
    "1. A `token_client_id` and a `token_client_secret`;\n",
    "2. a `token_url` (can be inferred from the Azure tenant-ID); and finally,\n",
    "3. a list of `token_scopes` (can usually be inferred from the CDF cluster). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02c37e9-3c8f-431f-a44a-cd7740120eb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from cognite.experimental import CogniteClient\n",
    "\n",
    "project      = \"<CDF project>\" # Fill in your project here\n",
    "cdf_cluster  = \"<CDF cluster>\" # Fill in the cluster your project is running in (for instance 'api'/'westeurope-1')\n",
    "\n",
    "tenant_id           = \"<Tenant ID>\"       # Fill in your Azure AD tenant ID here\n",
    "token_client_id     = \"<Token Client ID>\" # Fill in your Client ID here\n",
    "token_client_secret = getpass(\"Paste your `token_client_secret` in here: \")\n",
    "\n",
    "token_url = f\"https://login.microsoftonline.com/{tenant_id}/oauth2/v2.0/token\"\n",
    "token_scopes = [f\"https://{cdf_cluster}.cognitedata.com/.default\"]\n",
    "\n",
    "client = CogniteClient(\n",
    "    project = project,\n",
    "    server  = cdf_cluster,\n",
    "    client_name = \"My entity matcher\",\n",
    "    token_url = token_url,\n",
    "    token_scopes = token_scopes,\n",
    "    token_client_id = token_client_id,\n",
    "    token_client_secret = token_client_secret,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c01efe-5bb3-4ee7-afeb-277883a17737",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Getting a copy of test-data <a name=\"test-data\"></a>\n",
    "\n",
    "In this contextualization example we need some test data to test the entity matching functionality on. We have therefore provided a `publicdata.json`-file containing an asset hierarchy that will function as our test dataset. In this section, we ingest this data into your tenant, to get ready for the next few sections. Feel free to inspect the `publicdata.json`-file to get a feel for what the assets look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e900c0c-5e27-4657-b7ad-1fda1c6af15b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from cognite.client.data_classes import Asset, TimeSeries\n",
    "\n",
    "# We load the json-file into the `assets` and `time_series` lists.\n",
    "with open(\"publicdata.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    assets = data[\"assets\"]\n",
    "    time_series = data[\"time_series\"]\n",
    "    \n",
    "    print(f\"Found {len(assets)} assets and {len(time_series)} time series\")\n",
    "    \n",
    "# We then create Asset and TimeSeries objects, which is what the SDK expects.\n",
    "# We make sure to use id's from existing source as external_id + parent_external_id to preserve asset hierarchy.\n",
    "assets = [\n",
    "    Asset(name = asset[\"name\"], description = asset.get(\"description\"), external_id = asset[\"id\"], parent_external_id = asset.get(\"parent_id\"), source=\"publicdata\") \n",
    "    for asset in assets\n",
    "]\n",
    "time_series = [\n",
    "    TimeSeries(name = ts[\"name\"], description = ts.get(\"description\"), external_id = ts.get(\"external_id\"), metadata={\"source\": \"publicdata\"}) \n",
    "    for ts in time_series\n",
    "]\n",
    "\n",
    "# Finally, we use the `create_hierarchy` method from the SDK to ingest the whole asset hierarchy at once.\n",
    "# Similarly, we ingest the time series.\n",
    "try:\n",
    "    client.assets.create_hierarchy(assets)\n",
    "    print(f\"Created {len(assets)} assets\")\n",
    "except:\n",
    "    print(\"Failed to create assets. Probably already ingested these in a previous run\")\n",
    "    \n",
    "try: \n",
    "    client.time_series.create(time_series)\n",
    "    print(f\"Created {len(time_series)} time series\")\n",
    "except:\n",
    "    print(\"Failed to create time series. Probably already ingested these in a previous run\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1334a027-0efc-4a45-a201-46a85c81ead3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Defining, testing, and deploying our Cognite Function <a name=\"deploy-cog-fun\"></a>\n",
    "\n",
    "We are now ready to create the function that will run entity-matching on our newly ingested data. We define this in the file `handler.py`. Our function relies on the `cognite-sdk-experimental` package, so we need to specify this in a `requirements.txt`-file. We will deploy the function as showcased in `examples/02-creating-a-function-from-a-folder`, by deploying the entire folder.\n",
    "\n",
    "In brief, our function will perform the following:\n",
    "\n",
    "1. Since we need an experimental client to get the functionality we want, we must instantiate a new client on the inside of our function (the one we get through the argument `client` in `handle()` is a non-experimental `CogniteClient`). To do this, we use the `token` that is passed through the `secrets` argument.\n",
    "\n",
    "2. We fetch all the assets and time series we ingested earlier.\n",
    "\n",
    "3. Our goal is to map time-series to assets. We therefore create an entity matching model with `time_series` as sources, and `assets` as targets. \n",
    "\n",
    "4. We train our entity matching model (normally, this is a one-time operation, and the model can be reused. However, for simplicity sake, we train every time we call the function). \n",
    "\n",
    "5. We use the trained model to predict the time-series to asset mapping. We filter out items based on a threshold specified in the function `data` argument.\n",
    "\n",
    "6. Finally, we update the time series according to the predictions, to store the time-series to asset relationship.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d4b43c-6b27-4bc6-bff6-672e5ee8de91",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is good practice to test that the function works locally before deploying it to CDF. We do that here, by passing in our client, a data-dictionary with a threshold, and a token in the secrets-field (this token will be populated automatically when the function is deployed). \n",
    "Our function accepts a \"dry_run\" argument which we set to \"True\" when testing locally, to not do any inadvertent updates on the time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5b4ada-5622-4f64-a654-323e412cb898",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from handler import handle\n",
    "handle(client, {\"good_match_threshold\" : 0.75, \"dry_run\": True}, {\"token\" : client.config.token})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c6c26-43e4-4ca8-9593-a1cfa2f65c23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Deploying our function\n",
    "\n",
    "Having verified that the function does what we expect it do - we are ready to deploy it. We do that simply by calling `client.functions.create`, and pass in the `handle`-object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419f3bf-42d5-45e4-b893-ed7cca70fba3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "function = client.functions.create(\n",
    "    name = \"CogFun: Entity Matcher\",\n",
    "    external_id = \"entity_matcher_function\",\n",
    "    folder = \".\",\n",
    "    description = \"Performs entity matching, mapping time_series to assets\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94dd1f7-94d2-4b44-9712-ad89ffddc147",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "while function.status != \"Ready\":\n",
    "    function.update()\n",
    "    \n",
    "    if function.status == \"Failed\":        \n",
    "        print(\"Failed to deploy function\")\n",
    "        break\n",
    "else:\n",
    "    print(\"Function is successfully deployed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba89795-3e04-415b-bed6-057924493d4a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Calling our function <a name=\"calling-func\"></a>\n",
    "\n",
    "We can now call the function and get it's response and logs. Note how we do not need to supply a client or a token when calling it in CDF. This is supplied automatically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8859fa-92a6-48c9-b3a7-29bac768ebe7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = {\"good_match_threshold\": 0.75, \"dry_run\": False}\n",
    "call = function.call(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dd5818-517a-4541-b494-eff1a74d5159",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "f\"\"\"\n",
    "Function returned with:\n",
    "\n",
    "Logs: {call.get_logs()}\n",
    "Response: {call.get_response()}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0a733c-cc34-46d1-8926-307c3aba1e30",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Scheduling our function <a name=\"schedule-cog-fun\"></a>\n",
    "\n",
    "Consider the case we might want to run this entity matching job on a regular schedule to automatically match newly ingested time series to assets. We can do this by creating a Cognite Function Schedule.\n",
    "In order to do this, we need to pass in a set of client credentials (`client_id` and `client_secret`). In this example, for simplicity we will use the same client credentials we used to instantiate our client with (`token_client_id` and `token_client_secret` from above). However, for production use cases, you want to have a dedicated set of client credentials for your schedule.\n",
    "\n",
    "We create the function schedule by using the `client.functions.schedule.create`-method in the SDK. We use the crontab-format for specifying when the schedule should trigger a function call. If you have no prior experience with the crontab-format, see https://crontab.guru/ for an introduction. \n",
    "\n",
    "In this example, we want our schedule to run every minute. This corresponds to the cron expression `\"* * * * *\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d5cb0-c372-46a2-bc10-433bdaee7f8c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client_credentials = {'client_id': token_client_id, 'client_secret' : token_client_secret}\n",
    "schedule = client.functions.schedules.create(\n",
    "    name = \"run entity matching every minute\",\n",
    "    cron_expression = \"* * * * *\",             # the cron expression runs every minutes\n",
    "    function_id = function.id,                 # we specify the ID of the function we want to schedule\n",
    "    client_credentials = client_credentials,   # this is a dictionary with 'client_secret' and 'client_id'\n",
    "    data = {                                   # this is the data we wish to call the function with\n",
    "        \"good_match_threshold\":0.75,\n",
    "        \"dry_run\": False\n",
    "    },\n",
    "    description = \"Perform entity matching mapping time_series to assets every minute\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c5d25-cc72-46f6-a28c-df36ab45ec46",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In the Fusion UI you can now see a schedule has been created for the function in question. After a few minutes you should also see that the function is being automatically called. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01d54d5-84de-4257-9a54-b7a1d29af1e1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Cleanup\n",
    "\n",
    "In order to clean up after this example notebook, we can delete the function and the associated schedule that we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a43d5-084f-4d83-92c3-c645fb89927e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client.functions.delete(id=function.id) # This will also delete the function schedule tied to this function."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
